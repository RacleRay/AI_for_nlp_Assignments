{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:04:40.023761Z",
     "start_time": "2020-02-20T09:04:35.859762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=6, micro=8, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os, sys, time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:07:15.959330Z",
     "start_time": "2020-02-20T09:07:15.947336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "input_filepath = 'shakespeare.txt'\n",
    "with open(input_filepath, 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(len(text))\n",
    "print(text[: 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. vocab\n",
    "# 2. char -> id\n",
    "# 3. data -> ids\n",
    "# 4. input and output pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:29:10.934137Z",
     "start_time": "2020-02-20T09:29:10.730140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "\n",
    "char2idx = {char:idx for idx, char in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_ids = np.array([char2idx[char] for char in text])\n",
    "print(text_ids[: 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:29:39.943139Z",
     "start_time": "2020-02-20T09:29:39.915143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32) F\n",
      "tf.Tensor(47, shape=(), dtype=int32) i\n",
      "##############################\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int32)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int32)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_text):\n",
    "    return id_text[0: -1], id_text[1:]\n",
    "\n",
    "seq_len = 100\n",
    "char_data = tf.data.Dataset.from_tensor_slices(text_ids)\n",
    "# split_input_target中输入与输出相差一位\n",
    "seq_data = char_data.batch(seq_len + 1, drop_remainder=True)  # 生成句子\n",
    "for ch_id in char_data.take(2):\n",
    "    print(ch_id, idx2char[ch_id.numpy()])\n",
    "print('#' * 30)\n",
    "for seq_id in seq_data.take(2):\n",
    "    print(seq_id)\n",
    "    print(repr(''.join(idx2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:30:05.916139Z",
     "start_time": "2020-02-20T09:30:05.566139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1]\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1]\n",
      "[56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1 58\n",
      " 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0 13\n",
      " 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8  0\n",
      "  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1 63\n",
      " 53 59  1 49]\n"
     ]
    }
   ],
   "source": [
    "seq_data = seq_data.map(split_input_target)\n",
    "for ins, outs in seq_data.take(2):\n",
    "    print(ins.numpy())\n",
    "    print(outs.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:30:26.404139Z",
     "start_time": "2020-02-20T09:30:26.365142Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "seq_data = seq_data.shuffle(buffer_size).batch(batch_size,\n",
    "                                               drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:50:22.578882Z",
     "start_time": "2020-02-20T09:50:20.972869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (64, None, 1024)          1311744   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            66625     \n",
      "=================================================================\n",
      "Total params: 1,395,009\n",
      "Trainable params: 1,395,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_size = 256\n",
    "rnn_units = 1024\n",
    "\n",
    "def buid_model(vocab_size, embedding_size, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size, embedding_size,\n",
    "                               batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.LSTM(units=rnn_units,\n",
    "                               return_sequences=True,\n",
    "                               stateful=True,\n",
    "                               recurrent_initializer='glorot_uniform'),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = buid_model(vocab_size, embedding_size, rnn_units, batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:51:32.830398Z",
     "start_time": "2020-02-20T09:51:31.375431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n",
      "tf.Tensor(\n",
      "[50  2 19 35 16 14 41 13 18 26 26 24 58 63 18  1 16 42 27 17 30 57 53 57\n",
      " 16 46 54 38 60 25 54 57  1  3  8 17 14 45 48  8 21 59  9 55 60 19 20 58\n",
      " 57  5  2 52 57 58 43 60 55 45 32 61 56 22  0  9 57 39 63 25  2 26 53 13\n",
      "  4 20 39 60 45 35 58 39 51 10 11 60 50 47 61 40 54 19 53 57  2 11 23  8\n",
      " 45 34 28 18], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 随机sample\n",
    "for in_seq, out_seq in seq_data.take(1):\n",
    "    predictions = model.predict(in_seq)\n",
    "    print(predictions.shape)\n",
    "\n",
    "sample_idxs = tf.random.categorical(logits=predictions[0],\n",
    "                                    num_samples=1)\n",
    "print(tf.squeeze(sample_idxs, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T09:51:48.609399Z",
     "start_time": "2020-02-20T09:51:48.573429Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels, logits, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T10:24:10.056366Z",
     "start_time": "2020-02-20T09:52:36.926428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172/172 [==============================] - 22s 129ms/step - loss: 2.7587\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 2.0993\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.8740\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 1.7253\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 1.6280\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 1.5566\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.5068\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 1.4688\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.4378\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 1.4115\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 1.3899\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.3716\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 1.3546\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.3378\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 1.3238\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.3109\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 1.2988\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.2864\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.2750\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.2625\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.2537\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.2418\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.23250s - loss: \n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 1.2209\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.2123\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 20s 113ms/step - loss: 1.2015\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.1918\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 1.1840\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 1.1749\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.1641\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.1545\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.1458\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.1371\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.12961s \n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.1198\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.1086\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.1024\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 1.0950\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.0845\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.0776\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 1.0715\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 1.0644\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 1.0550\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.0474\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 1.0421\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 1.0363\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.0284\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 19s 113ms/step - loss: 1.0227\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 20s 118ms/step - loss: 1.0164\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.0119\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 1.0051\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 20s 116ms/step - loss: 1.0036\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 0.9944\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.9926\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 19s 112ms/step - loss: 0.9859\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.9832\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.9804\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 19s 110ms/step - loss: 0.9777\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9695\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9670\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9649\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9625\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9594\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9581\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9604\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9514\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9534\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9513\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9515\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9509\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9480\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9448\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9438\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9417\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9487\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.94821s - lo\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9441\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9419\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9436\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9469\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9454\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9453\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9489\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9484\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9459\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9507\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9506\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9506\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9553\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9571\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9532\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.9557\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.9626\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.9618\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.9583\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 18s 107ms/step - loss: 0.9631\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 0.9676\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 0.9693\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 19s 111ms/step - loss: 0.9709\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 0.9705\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_gen_checkpoints\"\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "checkpoint_prefix = os.path.join(output_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "epochs = 100\n",
    "history = model.fit(seq_data, epochs=epochs,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load and generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = buid_model(vocab_size, embedding_size, rnn_units, batch_size=1)\n",
    "model2.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "# 设置输入size\n",
    "model2.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# temperature > 1, predictions分布更均匀 ; < 1 predictions分布更集中\n",
    "\n",
    "def generate_text(model, start_str, num_generate=1000, temperature=1):\n",
    "    input_eval = [char2idx[ch] for ch in start_str]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    text = []\n",
    "    model.reset_states()\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = predictions / temperature\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        prediction_id = tf.random.categorical(\n",
    "            predictions, num_samples=1)[-1, 0].numpy()\n",
    "        text.append(idx2char[prediction_id])\n",
    "        input_eval = tf.expand_dims([prediction_id], 0)\n",
    "\n",
    "    return start_str + ''.join(text)\n",
    "\n",
    "res = generate_text(model2, \"You \")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
